
Making a science of model search

Many computer vision algorithms for scene classification take the form of a
pipeline of processing steps such as contrast normalization, linear filtering,
thresholding, subsampling, and reduction by histogram. Particular sequences,
with particular threshold levels and filters (or particular algorithms for
choosing them), make up the models that represent the state of the art
across a variety of image labeling tasks.  This paper describes a meta-model
for this sort of sequential signal processing approach. Our meta-model was
designed to span the approaches of [1] and [2], which are superficially quite
different and designed for very different tasks: object recognition in
thumbnail-sized images, and face-match verification [5,6].  We compare two
search procedures for exploring the meta-model space: random search and the
Tree of Parzen Estimators (TPE)[4].  By combining the approaches of [1] and
[2] we find several points in the meta-model search space that outperform the
approaches that were our inspiration.  More broadly, we argue that the
formalization of a meta-model confers several advantages and represents an
exciting direction for future work. A meta-model
1) can be searched by an algorithm, rather than a person;
2) provides an objective approach to establishing baselines on new tasks;
3) yeilds better-performing models;
4) provides an objective measure of which techniques work, how often, and
   in what combinations.


================================================================================

[1] Pinto & Cox (FG11)
[2] Coates & Ng (ICML11)
[3] Bergstra & Bengio (JMLR)
[4] Bergstra, Bardenet, Bengio, Kegl (NIPS11)
[5] Krizhevsky (for CIFAR10)
[6] ... Learned-Miller (for LFW)

